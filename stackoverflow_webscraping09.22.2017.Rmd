---
title: "webscraping09.22.2017"
author: "Shulin Qing"
date: "September 21, 2017"
output: html_document
---

```{r}

library(rvest)
library(knitr)
urls <- paste0("https://stackoverflow.com/jobs?sort=i&q=Data+Science&pg=", 1:7)

##names
names <- lapply(urls,
                function(url){
                fields <- url %>% read_html() %>% html_nodes(xpath='//*[contains(concat( " ", @class, " " ), concat( " ", "-job-item", " " ))]')
                names <-  fields %>% html_nodes(".-name") %>% 
                        html_text() %>% trimws()
                })

names = unlist(names)

##salaries
salaries <- lapply(urls,
                function(url){
                fields <- url %>% read_html() %>% html_nodes(xpath='//*[contains(concat( " ", @class, " " ), concat( " ", "-job-item", " " ))]')
                ### Not every job has salary listed
                fields %>% html_nodes(".-salary") %>% html_text()
                salaries <- sapply(fields, function(x) {
                tmp <- html_nodes(x, ".-salary") %>% html_text()
                 ifelse(length(tmp) == 0, "Not listed", trimws(tmp))})
                  salaries <- trimws(gsub("\\| \r\nEquity", "", salaries)) })
salaries = unlist(salaries)


##locations
locations <- lapply(urls,
                function(url){
                fields <- url %>% read_html() %>% html_nodes(xpath='//*[contains(concat( " ", @class, " " ), concat( " ", "-job-item", " " ))]')
                locations <- fields %>% html_nodes(".-location") %>% html_text() %>% trimws()
                locations <- gsub('- \r\n', "", locations)
                })

locations = unlist(locations)

##tags
tags <- lapply(urls,
                function(url){
                fields <- url %>% read_html() %>% html_nodes(xpath='//*[contains(concat( " ", @class, " " ), concat( " ", "-job-item", " " ))]')
                tags <- fields %>% html_nodes("div p") %>% html_text() %>% trimws()
                tags <- tags[!grepl("ago", tags)]
                })

### Get job urls
jobs.urls <- lapply(urls,
                function(url)
              {
                 fields <- url %>% read_html() %>% html_nodes(xpath='//*[contains(concat( " ", @class, " " ), concat( " ", "-job-item", " " ))]')
                x <- fields %>% html_nodes(".job-link") %>% html_attrs()
                job.urls = unname(unlist(sapply(x, function(x) if(x["class"]=="job-link") x["href"])))
                job.urls
                })
jobs.urls <- unlist(job.urls)
  
  res <- sapply(job.urls, function(x) {
   desc <- x %>% read_html() %>% html_nodes(".-job-description") %>% html_text() 
   python <- any(grepl("python", desc, ignore.case=TRUE))
   R <- any(grepl("\\bR\\b", desc, ignore.case=TRUE))
   SAS <- any(grepl("\\bSAS\\b", desc, ignore.case=TRUE))
   SQL <- any(grepl("\\bSQL\\b", desc, ignore.case=TRUE))
  Java <- any(grepl("\\bJava\\b", desc, ignore.case=TRUE))
  Tableau <- any(grepl("\\bTableau\\b", desc, ignore.case=TRUE))
   C<- any(grepl("\\bC\\b", desc, ignore.case=TRUE))
   Perl <- any(grepl("\\bPerl\\b", desc, ignore.case=TRUE))
   Excel <- any(grepl("\\bExcel\\b", desc, ignore.case=TRUE))
   c(Python=python,R=R,SAS=SAS,SQL=SQL,Java=Java,Tableau=Tableau,C=C,Perl=Perl,Excel=Excel)
})
               
res <- unname(res)

data <- data.frame("Company" = names, "Location"=locations, "Salary"=salaries, "Python"=res[1,], "R"=res[2,], "SAS"=res[3,], "SQL"=res[4,],"Java"=res[5,],"Tableau"=res[6,],"C"=res[7,],"Perl"=res[8,],"Excel"=res[9,])
nrow(data) #175
kable(data, format = "html")
```
